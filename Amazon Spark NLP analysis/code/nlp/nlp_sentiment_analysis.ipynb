{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bef463-9989-4f81-9b1d-357d20e2ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36f2dfc-4ad2-4ce0-88e5-871d26c3a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spark-nlp==4.2.1\n",
      "  Using cached spark_nlp-4.2.1-py2.py3-none-any.whl (643 kB)\n",
      "Installing collected packages: spark-nlp\n",
      "  Attempting uninstall: spark-nlp\n",
      "    Found existing installation: spark-nlp 4.2.1\n",
      "    Uninstalling spark-nlp-4.2.1:\n",
      "      Successfully uninstalled spark-nlp-4.2.1\n",
      "Successfully installed spark-nlp-4.2.1\n",
      "Requirement already satisfied: sparknlp in /mnt/miniconda/lib/python3.7/site-packages (1.0.0)\n",
      "Requirement already satisfied: spark-nlp in /mnt/miniconda/lib/python3.7/site-packages (from sparknlp) (4.2.1)\n",
      "Requirement already satisfied: numpy in /mnt/miniconda/lib/python3.7/site-packages (from sparknlp) (1.21.2)\n"
     ]
    }
   ],
   "source": [
    "!/mnt/miniconda/bin/pip install spark-nlp==4.2.1 --force\n",
    "!/mnt/miniconda/bin/pip install sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c716cada-c36c-4645-a88a-51731fac3287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/hadoop/.ivy2/cache\n",
      "The jars for the packages stored in: /home/hadoop/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/usr/lib/spark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-46068cbd-0f15-417a-b29d-2179893d0607;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.2.1 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 in central\n",
      ":: resolution report :: resolve 434ms :: artifacts dl 12ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.2.1 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.3 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   0   |   0   |   0   ||   17  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-46068cbd-0f15-417a-b29d-2179893d0607\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 17 already retrieved (0kB/14ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/03 21:24:35 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.johnsnowlabs.nlp_spark-nlp_2.12-4.2.1.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.typesafe_config-1.4.2.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.rocksdb_rocksdbjni-6.29.5.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.amazonaws_aws-java-sdk-bundle-1.11.828.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.github.universal-automata_liblevenshtein-3.0.0.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.navigamez_greex-1.0.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.johnsnowlabs.nlp_tensorflow-cpu_2.12-0.4.3.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.google.code.findbugs_annotations-3.0.1.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.google.protobuf_protobuf-java-util-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.google.protobuf_protobuf-java-3.0.0-beta-3.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/it.unimi.dsi_fastutil-7.0.12.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.projectlombok_lombok-1.16.8.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/org.slf4j_slf4j-api-1.7.21.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/net.jcip_jcip-annotations-1.0.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.1.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/com.google.code.gson_gson-2.3.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:41 WARN Client: Same path resource file:///home/hadoop/.ivy2/jars/dk.brics.automaton_automaton-1.11-8.jar added multiple times to distributed cache.\n",
      "23/04/03 21:24:48 WARN JettyUtils: GET /jobs/ failed: org.apache.spark.SparkException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "org.apache.spark.SparkException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:44)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:266)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:89)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:80)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:852)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1591)\n",
      "\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:192)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1591)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:542)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1307)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:482)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1204)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:494)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:374)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:268)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:103)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:918)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/04/03 21:24:48 WARN HttpChannel: /jobs/\n",
      "org.apache.spark.SparkException: Failed to get the application information. If you are starting up Spark, please wait a while until it's ready.\n",
      "\tat org.apache.spark.status.AppStatusStore.applicationInfo(AppStatusStore.scala:44)\n",
      "\tat org.apache.spark.ui.jobs.AllJobsPage.render(AllJobsPage.scala:266)\n",
      "\tat org.apache.spark.ui.WebUI.$anonfun$attachPage$1(WebUI.scala:89)\n",
      "\tat org.apache.spark.ui.JettyUtils$$anon$1.doGet(JettyUtils.scala:80)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:687)\n",
      "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHolder.handle(ServletHolder.java:852)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1604)\n",
      "\tat org.apache.spark.ui.HttpSecurityFilter.doFilter(HttpSecurityFilter.scala:95)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1591)\n",
      "\tat org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.doFilter(AmIpFilter.java:192)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1591)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:542)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1307)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\n",
      "\tat org.sparkproject.jetty.servlet.ServletHandler.doScope(ServletHandler.java:482)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1204)\n",
      "\tat org.sparkproject.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
      "\tat org.sparkproject.jetty.server.handler.gzip.GzipHandler.handle(GzipHandler.java:772)\n",
      "\tat org.sparkproject.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221)\n",
      "\tat org.sparkproject.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
      "\tat org.sparkproject.jetty.server.Server.handle(Server.java:494)\n",
      "\tat org.sparkproject.jetty.server.HttpChannel.handle(HttpChannel.java:374)\n",
      "\tat org.sparkproject.jetty.server.HttpConnection.onFillable(HttpConnection.java:268)\n",
      "\tat org.sparkproject.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
      "\tat org.sparkproject.jetty.io.FillInterest.fillable(FillInterest.java:103)\n",
      "\tat org.sparkproject.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\n",
      "\tat org.sparkproject.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:918)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"SparkNLP\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:4.2.1\") \\\n",
    "    .master('yarn') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d803b10-4212-4603-90d9-0586aa044976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-14-208.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkNLP</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2cb40d5e10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ab8b7d-1af9-459a-a4cf-31dc7b3f00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.annotator import *\n",
    "from sparknlp.base import *\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a5da1da-c6eb-4e0a-a2b0-1ff2a0ea1b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |████████████████████████████████| 125 kB 29.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /mnt/miniconda/lib/python3.7/site-packages (from vaderSentiment) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/miniconda/lib/python3.7/site-packages (from requests->vaderSentiment) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/miniconda/lib/python3.7/site-packages (from requests->vaderSentiment) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /mnt/miniconda/lib/python3.7/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/miniconda/lib/python3.7/site-packages (from requests->vaderSentiment) (3.3)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!/mnt/miniconda/bin/pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2900c75-a9bc-424c-a27f-6141f7a5a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Vader sentiment labeler \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ff95c0b-2340-4585-9972-f66ec9007233",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the data\n",
    "df_sub_processed = spark.read.parquet(\"s3a://ppol567-llj40-bucket-3/preprocessed_submissions\")\n",
    "df_com_processed = spark.read.parquet(\"s3a://ppol567-llj40-bucket-3/preprocessed_comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1b58302-3337-4b37-9a2f-34ea1673db02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146327\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- date_clean: date (nullable = true)\n",
      " |-- Live_Thread: boolean (nullable = true)\n",
      " |-- War_Dummy: boolean (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:======================================================>  (25 + 1) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16171595\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- date_clean: date (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Viewing the specs\n",
    "print(df_sub_processed.count())\n",
    "df_sub_processed.printSchema()\n",
    "\n",
    "print(df_com_processed.count())\n",
    "df_com_processed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b88fb6c-28a9-4fa7-885a-c9f6d3d62c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+----------+-----------+---------+--------------------+\n",
      "|     id|               title|created_date|date_clean|Live_Thread|War_Dummy|      finished_clean|\n",
      "+-------+--------------------+------------+----------+-----------+---------+--------------------+\n",
      "| zuu0wk|\"Ein irreparabler...|  12-25-2022|2022-12-25|      false|     true|[ein, irreparable...|\n",
      "| tfxnq4|\"Good luck with t...|  03-17-2022|2022-03-17|      false|    false|        [good, luck]|\n",
      "| uaxrfp|\"No one betrayed ...|  04-24-2022|2022-04-24|      false|    false|[betray, village,...|\n",
      "| tghuvb|\"Russian warship,...|  03-17-2022|2022-03-17|      false|     true|[russian, warship...|\n",
      "|10imxsx|#BBTitans: Yemi s...|  01-22-2023|2023-01-22|      false|    false|[bbtitans, yemi, ...|\n",
      "+-------+--------------------+------------+----------+-----------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sub_processed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10d55816-a1d8-4407-8841-b7e59db8949b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+\n",
      "|     id|submission_id|created_date|date_clean|                body|controversiality|      finished_clean|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+\n",
      "|hya5fg8|       t0h8af|  02-24-2022|2022-02-24|Isnt reddit alway...|               1|[isnt, reddit, an...|\n",
      "|hya5fgw|       t0i53m|  02-24-2022|2022-02-24| tf are you on about|               0|                [tf]|\n",
      "|hya5fkj|       t0i53m|  02-24-2022|2022-02-24|I believe it is t...|               0|[short, path, kyi...|\n",
      "|hya5fl1|       t0br75|  02-24-2022|2022-02-24|Because Fox \"News...|               0|[fox, news, 90, m...|\n",
      "|hya5fli|       t079w7|  02-24-2022|2022-02-24|The last one make...|               0|[make, lot, sense...|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_com_processed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44decdc-5b1c-44a3-8277-0ff9414af346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|     id|submission_id|created_date|date_clean|                body|controversiality|      finished_clean|         string_form|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|hya5fg8|       t0h8af|  02-24-2022|2022-02-24|Isnt reddit alway...|               1|[isnt, reddit, an...|isnt reddit angry...|\n",
      "|hya5fgw|       t0i53m|  02-24-2022|2022-02-24| tf are you on about|               0|                [tf]|                  tf|\n",
      "|hya5fkj|       t0i53m|  02-24-2022|2022-02-24|I believe it is t...|               0|[short, path, kyi...|short path kyiv n...|\n",
      "|hya5fl1|       t0br75|  02-24-2022|2022-02-24|Because Fox \"News...|               0|[fox, news, 90, m...|fox news 90 milli...|\n",
      "|hya5fli|       t079w7|  02-24-2022|2022-02-24|The last one make...|               0|[make, lot, sense...|make lot sense ol...|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Creating a new column for the sentence to apply sentence embeddings and implement goal specific processing. \n",
    "df_sub_processed = df_sub_processed.withColumn(\"string_form\", f.concat_ws(\" \", col(\"finished_clean\")))\n",
    "df_com_processed = df_com_processed.withColumn(\"string_form\", f.concat_ws(\" \", col(\"finished_clean\")))\n",
    "df_com_processed.show(5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dea56473-e75b-4afb-ae16-80253c4d74cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Only accessing live thread submissions and comments \n",
    "df_live_sub = df_sub_processed.filter(col(\"Live_Thread\") == 1)\n",
    "\n",
    "### Getting the live thread ids \n",
    "df_sub_live_id = df_live_sub.select(\"id\").collect()\n",
    "df_sub_live_id = [row.id for row in df_sub_id]\n",
    "\n",
    "### Extracting the live thread comments \n",
    "df_live_com = df_com_processed.filter(col(\"submission_id\").isin(df_sub_live_id))\n",
    "df_live_com.count()\n",
    "\n",
    "### Removing comments from subreddit moderators \n",
    "df_live_com = df_live_com.withColumn(\"moderator\", col(\"string_form\").rlike(\"(?i)moderator\"))\n",
    "df_live_clean = df_live_com.filter(col(\"moderator\") == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fea91c5a-631e-476b-b922-c6bbfc47326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_twitter download started this may take some time.\n",
      "Approximate size to download 11.4 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "### Model 1 twitter sentiment analyser \n",
    "MODEL_1 = 'sentimentdl_use_twitter'\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"string_form\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\") \\\n",
    " .setInputCols([\"document\"]) \\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentdl = SentimentDLModel.pretrained(name=MODEL_1, lang=\"en\") \\\n",
    "    .setInputCols([\"sentence_embeddings\"]) \\\n",
    "    .setOutputCol(\"sentiment\")\n",
    "                \n",
    "sentiment_pipeline_1 = Pipeline(stages = [documentAssembler,\n",
    "                                       use,\n",
    "                                       sentimentdl\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e20241a1-ad6e-44be-b826-40a7c263dd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_vivekn download started this may take some time.\n",
      "Approximate size to download 873.6 KB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "### Model 2 vivekn sentiment analyser\n",
    "documentAssembler = DocumentAssembler() \\\n",
    ".setInputCol(\"string_form\") \\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    ".setInputCols([\"document\"]) \\\n",
    ".setOutputCol(\"tokenized\")\n",
    "\n",
    "normalizer = Normalizer() \\\n",
    ".setInputCols([\"tokenized\"]) \\\n",
    ".setOutputCol(\"normalized\")\n",
    "\n",
    "vivekn =  ViveknSentimentModel.pretrained() \\\n",
    ".setInputCols([\"document\", \"normalized\"]) \\\n",
    ".setOutputCol(\"vn_sentiment\")\n",
    "\n",
    "finisher = Finisher() \\\n",
    ".setInputCols([\"vn_sentiment\"]) \\\n",
    ".setOutputCols(\"sentiment\")\n",
    "\n",
    "vivek_sentiment_pipeline = Pipeline(stages = [documentAssembler,\n",
    "                                       tokenizer,\n",
    "                                       normalizer,\n",
    "                                       vivekn,\n",
    "                                       finisher\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a70f1c4e-3a1e-4248-8b70-59e07d04a4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfhub_use download started this may take some time.\n",
      "Approximate size to download 923.7 MB\n",
      "[OK!]\n",
      "sentimentdl_use_imdb download started this may take some time.\n",
      "Approximate size to download 12 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "### Model 3 \n",
    "MODEL_3 = \"sentimentdl_use_imdb\"\n",
    "\n",
    "documentAssembler = DocumentAssembler() \\\n",
    "    .setInputCol(\"string_form\") \\\n",
    "    .setOutputCol(\"document\")\n",
    "    \n",
    "use = UniversalSentenceEncoder.pretrained(name=\"tfhub_use\", lang=\"en\") \\\n",
    " .setInputCols([\"document\"]) \\\n",
    " .setOutputCol(\"sentence_embeddings\")\n",
    "\n",
    "sentimentDl = SentimentDLModel.pretrained(name = MODEL_3, lang = 'en') \\\n",
    "                                          .setInputCols(\"sentence_embeddings\") \\\n",
    "                                          .setOutputCol(\"sentiment\")\n",
    "\n",
    "sentiment_pipeline_3 = Pipeline(stages = [documentAssembler,\n",
    "                                       use,\n",
    "                                       sentimentdl\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "342df232-f9cc-4c8a-b7bb-a1433f78d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training the three models on the live thread comments dataset \n",
    "## Model 1\n",
    "sentiment_model_1 = sentiment_pipeline_1.fit(df_live_clean)\n",
    "result_1 = sentiment_model_1.transform(df_live_clean)\n",
    "\n",
    "## Model 2\n",
    "sentiment_model_2 = vivek_sentiment_pipeline.fit(df_live_clean)\n",
    "result_2 = sentiment_model_2.transform(df_live_clean)\n",
    "\n",
    "## Model 3 \n",
    "sentiment_model_3 = sentiment_pipeline_3.fit(df_live_clean)\n",
    "result_3 = sentiment_model_3.transform(df_live_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1b04d9f9-18ee-4b51-842f-3f4302eb867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Extracting the sentiments \n",
    "result_1 = result_1.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_2 = result_2.select(\"id\", f.explode(col(\"sentiment\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_3 = result_3.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "\n",
    "total_count = result_2.count()\n",
    "\n",
    "\n",
    "### Aggregating the results \n",
    "result_1_agg = result_1.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_2_agg = result_2.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_3_agg = result_3.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e8b78515-2223-47f3-9c5b-a115632916a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_602/3720299016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_1_agg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mr_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Proportion of Comments\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Proportion of Comments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:,.2f}%\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mr_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/miniconda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mround\u001b[0;34m(self, decimals, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2391\u001b[0m         \"\"\"\n\u001b[1;32m   2392\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m         result = self._constructor(result, index=self.index).__finalize__(\n\u001b[1;32m   2395\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"round\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "### Formatting the results \n",
    "r_1 = result_1_agg\n",
    "r_1[\"Proportion of Comments\"] = r_1[\"Proportion of Comments\"].round(2).map(\"{:,.2f}%\".format)\n",
    "r_1\n",
    "\n",
    "r_2 = result_2_agg\n",
    "r_2[\"Proportion of Comments\"] = r_2[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_2\n",
    "\n",
    "r_3 = result_3_agg\n",
    "r_3[\"Proportion of Comments\"] = r_3[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9c481456-15b4-4ac8-9cda-88bf1d5b18c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IMDB Sentiment Analyzer</th>\n",
       "      <td>52.54%</td>\n",
       "      <td>4.32%</td>\n",
       "      <td>43.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twitter Sentiment Analyzer</th>\n",
       "      <td>52.54%</td>\n",
       "      <td>4.32%</td>\n",
       "      <td>43.30%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vivek Sentiment Analyzer</th>\n",
       "      <td>44.78%</td>\n",
       "      <td>18.91%</td>\n",
       "      <td>36.30%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment                  negative neutral positive\n",
       "Model                                               \n",
       "IMDB Sentiment Analyzer      52.54%   4.32%   43.30%\n",
       "Twitter Sentiment Analyzer   52.54%   4.32%   43.30%\n",
       "Vivek Sentiment Analyzer     44.78%  18.91%   36.30%"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatinating the results and displaying as table \n",
    "r_list = [r_1, r_2, r_3]\n",
    "results_final = pd.concat(r_list)\n",
    "Models = [\"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\",\\\n",
    "          \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \\\n",
    "          \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\"]\n",
    "r_f = results_final\n",
    "r_f[\"sentiment\"] = r_f[\"sentiment\"].str.replace(\"na\", \"neutral\")\n",
    "r_f = r_f.assign(Model = Models)\n",
    "r_f = r_f.pivot(values = \"Proportion of Comments\", columns = \"sentiment\", index = \"Model\")\n",
    "r_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2e9546c-ea6c-4aff-aa9e-b2c63b542bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving the table \n",
    "r_f.to_csv(\"sentiment_results_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1d1667c6-d4a0-4709-8c40-9c75bd0da906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of submissions pertaining to the war :  61960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/04 02:33:06 WARN DAGScheduler: Broadcasting large task binary with size 1717.6 KiB\n",
      "[Stage 67:=====================================================>  (25 + 1) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of comments pertaining to the war :  6359956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Russia-Ukraine War comments excluding the live threads \n",
    "war_ids = df_sub_processed.filter(\"War_Dummy == true\").filter(\"Live_Thread == false\").select(\"id\").collect()\n",
    "war_ids = [row.id for row in war_ids]\n",
    "\n",
    "### War submissions\n",
    "war_submission = df_sub_processed.filter(\"War_Dummy == true\").filter(\"Live_Thread == false\")\n",
    "print(\"The number of submissions pertaining to the war : \", war_submission.count())\n",
    "\n",
    "### War Comments \n",
    "war_comment = df_com_processed.filter(col(\"submission_id\").isin(war_ids))\n",
    "print(\"The number of comments pertaining to the war : \", war_comment.count())\n",
    "\n",
    "### Removing comments from subreddit moderators \n",
    "war_comment = war_comment.withColumn(\"moderator\", col(\"string_form\").rlike(\"(?i)moderator\"))\n",
    "war_comment_clean = war_comment.filter(col(\"moderator\") == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ee858558-a06f-494c-98aa-ea982ade53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training on the three models on war submissions  \n",
    "## Model 1\n",
    "sentiment_model_1 = sentiment_pipeline_1.fit(war_submission)\n",
    "result_1 = sentiment_model_1.transform(war_submission).cache()\n",
    "\n",
    "## Model 2\n",
    "sentiment_model_2 = vivek_sentiment_pipeline.fit(war_submission)\n",
    "result_2 = sentiment_model_2.transform(war_submission).cache()\n",
    "\n",
    "## Model 3 \n",
    "sentiment_model_3 = sentiment_pipeline_3.fit(war_submission)\n",
    "result_3 = sentiment_model_3.transform(war_submission).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6592354b-b9a1-4f75-af9f-08fac2c1efac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Extracting the sentiments \n",
    "result_1 = result_1.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_2 = result_2.select(\"id\", f.explode(col(\"sentiment\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_3 = result_3.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "\n",
    "total_count = result_2.count()\n",
    "\n",
    "\n",
    "### Aggregating the results \n",
    "result_1_agg = result_1.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_2_agg = result_2.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_3_agg = result_3.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f1313c78-e1b7-4b79-9e55-100dd4566733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Proportion of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>20.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>77.90%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment Proportion of Comments\n",
       "0  positive                 20.85%\n",
       "1   neutral                  1.25%\n",
       "2  negative                 77.90%"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Formatting the results \n",
    "r_1 = result_1_agg\n",
    "r_1[\"Proportion of Comments\"] = r_1[\"Proportion of Comments\"].round(2).map(\"{:,.2f}%\".format)\n",
    "r_1\n",
    "\n",
    "r_2 = result_2_agg\n",
    "r_2[\"Proportion of Comments\"] = r_2[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_2\n",
    "\n",
    "r_3 = result_3_agg\n",
    "r_3[\"Proportion of Comments\"] = r_3[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ec321487-9fe2-41b5-84b2-57e850f3e99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Proportion of Comments</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>20.85%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>77.90%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>24.54%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>30.27%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>45.19%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>20.85%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>77.90%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Submissions</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment Proportion of Comments                       Model         Type\n",
       "0  positive                 20.85%  Twitter Sentiment Analyzer  Submissions\n",
       "1   neutral                  1.25%  Twitter Sentiment Analyzer  Submissions\n",
       "2  negative                 77.90%  Twitter Sentiment Analyzer  Submissions\n",
       "0  positive                 24.54%    Vivek Sentiment Analyzer  Submissions\n",
       "1   neutral                 30.27%    Vivek Sentiment Analyzer  Submissions\n",
       "2  negative                 45.19%    Vivek Sentiment Analyzer  Submissions\n",
       "0  positive                 20.85%     IMDB Sentiment Analyzer  Submissions\n",
       "1   neutral                  1.25%     IMDB Sentiment Analyzer  Submissions\n",
       "2  negative                 77.90%     IMDB Sentiment Analyzer  Submissions"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatinating the results and displaying as table \n",
    "r_list = [r_1, r_2, r_3]\n",
    "results_final = pd.concat(r_list)\n",
    "Models = [\"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\",\\\n",
    "          \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \\\n",
    "          \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\"]\n",
    "r_f_1 = results_final\n",
    "r_f_1[\"sentiment\"] = r_f_1[\"sentiment\"].str.replace(\"na\", \"neutral\")\n",
    "r_f_1 = r_f_1.assign(Model = Models)\n",
    "r_f_1[\"Type\"] = \"Submissions\"\n",
    "#r_f_1 = r_f_1.pivot(values = \"Proportion of Comments\", columns = \"sentiment\", index = \"Model\")\n",
    "r_f_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4a9b5ce5-8356-4c4c-b73e-2be93a2b290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training on the three models on war comments \n",
    "## Model 1\n",
    "sentiment_model_1 = sentiment_pipeline_1.fit(war_comment_clean)\n",
    "result_1 = sentiment_model_1.transform(war_comment_clean)\n",
    "\n",
    "## Model 2\n",
    "sentiment_model_2 = vivek_sentiment_pipeline.fit(war_comment_clean)\n",
    "result_2 = sentiment_model_2.transform(war_comment_clean)\n",
    "\n",
    "## Model 3 \n",
    "sentiment_model_3 = sentiment_pipeline_3.fit(war_comment_clean)\n",
    "result_3 = sentiment_model_3.transform(war_comment_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "14f16d06-6441-4095-b47c-cce043af34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/04 05:14:25 WARN DAGScheduler: Broadcasting large task binary with size 2.8 MiB\n",
      "23/04/04 05:19:54 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/04/04 05:44:26 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "23/04/04 05:44:31 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/04/04 05:49:57 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "23/04/04 05:50:02 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/04/04 06:13:56 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Extracting the sentiments \n",
    "result_1 = result_1.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_2 = result_2.select(\"id\", f.explode(col(\"sentiment\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "result_3 = result_3.select(\"id\", f.explode(col(\"sentiment.result\"))).withColumnRenamed(\"col\", \"sentiment\")\n",
    "\n",
    "total_count = result_2.count()\n",
    "\n",
    "\n",
    "### Aggregating the results \n",
    "result_1_agg = result_1.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_2_agg = result_2.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n",
    "\n",
    "result_3_agg = result_3.groupby(\"sentiment\") \\\n",
    "                       .agg((f.count(col(\"sentiment\"))/total_count*100).alias(\"Proportion of Comments\")).toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c399388b-922c-4984-90d5-a831e3b1d8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Proportion of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>43.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>4.26%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>52.68%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment Proportion of Comments\n",
       "0  positive                 43.16%\n",
       "1   neutral                  4.26%\n",
       "2  negative                 52.68%"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Formatting the results \n",
    "r_1 = result_1_agg\n",
    "r_1[\"Proportion of Comments\"] = r_1[\"Proportion of Comments\"].round(2).map(\"{:,.2f}%\".format)\n",
    "r_1\n",
    "\n",
    "r_2 = result_2_agg\n",
    "r_2[\"Proportion of Comments\"] = r_2[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_2\n",
    "\n",
    "r_3 = result_3_agg\n",
    "r_3[\"Proportion of Comments\"] = r_3[\"Proportion of Comments\"].map(\"{:,.2f}%\".format)\n",
    "r_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c134172a-816e-4191-917a-4ff391f26617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Proportion of Comments</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>43.16%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>52.68%</td>\n",
       "      <td>Twitter Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>36.18%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>17.10%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>46.72%</td>\n",
       "      <td>Vivek Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>43.16%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>52.68%</td>\n",
       "      <td>IMDB Sentiment Analyzer</td>\n",
       "      <td>Comments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment Proportion of Comments                       Model      Type\n",
       "0  positive                 43.16%  Twitter Sentiment Analyzer  Comments\n",
       "1   neutral                  4.26%  Twitter Sentiment Analyzer  Comments\n",
       "2  negative                 52.68%  Twitter Sentiment Analyzer  Comments\n",
       "0  positive                 36.18%    Vivek Sentiment Analyzer  Comments\n",
       "1   neutral                 17.10%    Vivek Sentiment Analyzer  Comments\n",
       "2  negative                 46.72%    Vivek Sentiment Analyzer  Comments\n",
       "0  positive                 43.16%     IMDB Sentiment Analyzer  Comments\n",
       "1   neutral                  4.26%     IMDB Sentiment Analyzer  Comments\n",
       "2  negative                 52.68%     IMDB Sentiment Analyzer  Comments"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Concatenating the results and displaying as table \n",
    "r_list = [r_1, r_2, r_3]\n",
    "results_final = pd.concat(r_list)\n",
    "Models = [\"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\", \"Twitter Sentiment Analyzer\",\\\n",
    "          \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \"Vivek Sentiment Analyzer\", \\\n",
    "          \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\", \"IMDB Sentiment Analyzer\"]\n",
    "r_f_2 = results_final\n",
    "r_f_2[\"sentiment\"] = r_f_2[\"sentiment\"].str.replace(\"na\", \"neutral\")\n",
    "r_f_2 = r_f_2.assign(Model = Models)\n",
    "r_f_2[\"Type\"] = \"Comments\"\n",
    "r_f_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c7f704d5-3401-41d5-ae90-f5c52d35d895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">IMDB Sentiment Analyzer</th>\n",
       "      <th>Comments</th>\n",
       "      <td>52.68%</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>43.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submissions</th>\n",
       "      <td>77.90%</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>20.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Twitter Sentiment Analyzer</th>\n",
       "      <th>Comments</th>\n",
       "      <td>52.68%</td>\n",
       "      <td>4.26%</td>\n",
       "      <td>43.16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submissions</th>\n",
       "      <td>77.90%</td>\n",
       "      <td>1.25%</td>\n",
       "      <td>20.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Vivek Sentiment Analyzer</th>\n",
       "      <th>Comments</th>\n",
       "      <td>46.72%</td>\n",
       "      <td>17.10%</td>\n",
       "      <td>36.18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Submissions</th>\n",
       "      <td>45.19%</td>\n",
       "      <td>30.27%</td>\n",
       "      <td>24.54%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sentiment                              negative neutral positive\n",
       "Model                      Type                                 \n",
       "IMDB Sentiment Analyzer    Comments      52.68%   4.26%   43.16%\n",
       "                           Submissions   77.90%   1.25%   20.85%\n",
       "Twitter Sentiment Analyzer Comments      52.68%   4.26%   43.16%\n",
       "                           Submissions   77.90%   1.25%   20.85%\n",
       "Vivek Sentiment Analyzer   Comments      46.72%  17.10%   36.18%\n",
       "                           Submissions   45.19%  30.27%   24.54%"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_list = [r_f_1, r_f_2]\n",
    "rf_final = pd.concat(rf_list)\n",
    "table_2 = rf_final \n",
    "table_2 = table_2.pivot(values = \"Proportion of Comments\", columns = \"sentiment\", index = [\"Model\", \"Type\"])\n",
    "table_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5175d801-c1e6-46d5-8031-53fd5d6f499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_2.to_csv(\"sentiment_results_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3c159830-7099-4be0-bd64-212c3e022673",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
