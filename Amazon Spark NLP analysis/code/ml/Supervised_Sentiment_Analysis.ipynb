{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ac1e74-e611-4637-b576-e8c0b606e6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/04/13 23:41:06 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n",
      "23/04/13 23:41:13 WARN YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to request executors before the AM has registered!\n"
     ]
    }
   ],
   "source": [
    "### Importing required libraries \n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### Import Vader sentiment labeler \n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "### Spark ML \n",
    "from pyspark.ml import Pipeline, Model\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler, HashingTF, IDF\n",
    "from pyspark.ml.classification import LogisticRegression, OneVsRest, NaiveBayes, MultilayerPerceptronClassifier, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
    "\n",
    "spark = SparkSession.builder.appName(\"reddit-bigdata-project\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49aef4c0-ce76-4580-bc5f-30648adeb117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-30-249.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-amzn-0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>reddit-bigdata-project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb1935283d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fff0597-1b16-41df-b4e0-8c6b9f0a4c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Reading in the data\n",
    "df_sub_processed = spark.read.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/submissions_preprocessed\")\n",
    "df_com_processed = spark.read.parquet(\"s3a://ppol567-llj40-bucket-4/comments_preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dfae04e-bc66-4869-8495-6382d20e7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- date_clean: date (nullable = true)\n",
      " |-- Live_Thread: boolean (nullable = true)\n",
      " |-- War_Dummy: boolean (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146327\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- date_clean: date (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:======================================================> (27 + 1) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16171595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sub_processed.printSchema()\n",
    "print(df_sub_processed.count())\n",
    "df_com_processed.printSchema()\n",
    "print(df_com_processed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46650f85-4bb0-4353-a996-6dbe3d5874a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|     id|submission_id|created_date|date_clean|                body|controversiality|      finished_clean|         string_form|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "|hytxcbv|       t3pr7i|  02-28-2022|2022-02-28|Also calling the ...|               0|[call, people, ho...|call people hosta...|\n",
      "|hytxccf|       t3jzfh|  02-28-2022|2022-02-28|Had to read this ...|               0|              [read]|                read|\n",
      "|hytxcd8|       t3pr7i|  02-28-2022|2022-02-28|I think it is up ...|               0|[23rds, limit, av...|23rds limit avenu...|\n",
      "|hytxcdm|       t139g6|  02-28-2022|2022-02-28|I see your answer...|               0|[answer, question...|answer question w...|\n",
      "|hytxcdq|       t3gw0b|  02-28-2022|2022-02-28|How sweet that yo...|               0|[sweet, worry, of...|sweet worry offen...|\n",
      "+-------+-------------+------------+----------+--------------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Creating a new column for the sentence to apply sentence embeddings and implement goal specific processing. \n",
    "df_sub_processed = df_sub_processed.withColumn(\"string_form\", f.concat_ws(\" \", col(\"finished_clean\")))\n",
    "df_com_processed = df_com_processed.withColumn(\"string_form\", f.concat_ws(\" \", col(\"finished_clean\")))\n",
    "df_com_processed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d68aa718-e375-409b-a3fc-ea0d12efeadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3233187"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Labelling only ~3.1 million comments \n",
    "df_sentiment_label = df_com_processed.sample(False, 0.2, seed = 9)\n",
    "df_sentiment_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fef27cfc-1599-4463-b232-93ff94882cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Further cleaning of text \n",
    "### Removing comments from subreddit moderators \n",
    "df_sentiment_label = df_sentiment_label.withColumn(\"moderator\", col(\"string_form\").rlike(\"(?i)moderator\"))\n",
    "df_sentiment_label_clean = df_sentiment_label.filter(col(\"moderator\") == False)\n",
    "\n",
    "### Removing empty rows \n",
    "df_sentiment_label_clean = df_sentiment_label_clean.filter(f.col(\"string_form\") != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66dccaeb-d4d4-40e2-8d62-e234ed245e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3177282"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_label_clean.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae1dd134-b2a3-4b73-b6db-43f9efab710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Instantiating the Vader Sentiment Analyzer \n",
    "sa_model = SentimentIntensityAnalyzer()\n",
    "\n",
    "### Registering the method \n",
    "udf_1 = f.udf(lambda z : sa_model.polarity_scores(z))\n",
    "udf_2 = f.udf(lambda z : z[\"compound\"])\n",
    "udf_3 = f.udf(lambda z : z[\"pos\"])\n",
    "udf_4 = f.udf(lambda z : z[\"neg\"])\n",
    "udf_5 = f.udf(lambda z : z[\"neu\"])\n",
    "\n",
    "df_sentiment_label_clean = df_sentiment_label_clean.withColumn(\"Polarity_Scores\", udf_1(f.col(\"string_form\")))\\\n",
    "                                                   .withColumn(\"Compound_Score\", udf_2(f.col(\"Polarity_Scores\"))) \\\n",
    "                                                   .withColumn(\"Positive_Score\", udf_3(f.col(\"Polarity_Scores\"))) \\\n",
    "                                                   .withColumn(\"Negative_Score\", udf_4(f.col(\"Polarity_Scores\"))) \\\n",
    "                                                   .withColumn(\"Neutral_Score\", udf_5(f.col(\"Polarity_Scores\"))) \\\n",
    "                                                   .withColumn(\"Sentiment_Label\", when(f.col(\"Compound_Score\") < -0.05, \"Negative\") \\\n",
    "                                                                                  .when(f.col(\"Compound_Score\") > 0.05, \"Positive\")  \\\n",
    "                                                                                  .otherwise(\"Neutral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80123300-fcce-4ace-b9e7-6d664d06b9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/10 15:33:44 WARN DAGScheduler: Broadcasting large task binary with size 1053.6 KiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sentiment_label_clean.select(\"id\", \"submission_id\", \"finished_clean\", \"string_form\", \\\n",
    "                                \"Polarity_Scores\", \"Compound_Score\", \"Positive_Score\", \\\n",
    "                                \"Negative_Score\", \"Neutral_Score\", \"Sentiment_Label\").write.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/sentiment_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aabcbc24-f289-4eee-9ba5-ab4fcb727559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 48:======================================================> (27 + 1) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------+\n",
      "|Sentiment Label|  count|\n",
      "+---------------+-------+\n",
      "|       Positive| 952184|\n",
      "|        Neutral| 878283|\n",
      "|       Negative|1346815|\n",
      "+---------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Displaying the classes\n",
    "df_sentiment_label_clean.groupby(\"Sentiment Label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41680c3a-04e4-4eb0-9a0e-de1c2c00c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d88d8-8b6b-47eb-a755-d638030bc457",
   "metadata": {},
   "source": [
    "### Supervised Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2028fcab-e41c-4220-bbc3-307afe0d663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing the data \n",
    "df_sentiment = spark.read.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/sentiment_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff2f3c3a-478e-46ef-9071-15cdecfac6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:======================================================>  (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3177282\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = true)\n",
      " |-- Polarity_Scores: string (nullable = true)\n",
      " |-- Compound_Score: string (nullable = true)\n",
      " |-- Positive_Score: string (nullable = true)\n",
      " |-- Negative_Score: string (nullable = true)\n",
      " |-- Neutral_Score: string (nullable = true)\n",
      " |-- Sentiment_Label: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(df_sentiment.count())\n",
    "df_sentiment.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4227b278-3025-4817-88ab-314d48692574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Splitting into training and testing data \n",
    "train_data, test_data = df_sentiment.randomSplit([0.8, 0.2], seed = 9)\n",
    "\n",
    "### Applying TF-IDF to the string \n",
    "h_t = HashingTF(inputCol = \"finished_clean\", outputCol = \"tf_features\")\n",
    "tf_train = h_t.transform(train_data)\n",
    "\n",
    "### Inverse document frequency \n",
    "idf = IDF(inputCol = \"tf_features\", outputCol = \"TF_IDF_features\", minDocFreq = 1)\n",
    "### Fitting only the train_data dataset \n",
    "idf_model = idf.fit(tf_train)\n",
    "\n",
    "\n",
    "### Applying string indexer to the target array Sentiment_Label \n",
    "string_indexer_target = StringIndexer(inputCol = \"Sentiment_Label\", outputCol = \"label\")\n",
    "string_idx_model = string_indexer_target.fit(train_data)\n",
    "\n",
    "### Setting the feature matrix \n",
    "vectorAssembler_features = VectorAssembler(\n",
    "    inputCols=[\"TF_IDF_features\"], \n",
    "    outputCol= \"features\")\n",
    "\n",
    "### Instantiating the model (Hyperparameter tuning of Logistic Regression necessary) \n",
    "lr = LogisticRegression(maxIter=10, tol=1E-6, fitIntercept=True)\n",
    "ovr = OneVsRest(classifier = lr, labelCol = \"label\", featuresCol = \"features\")\n",
    "\n",
    "### Multinomial Naive Bayes\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\", labelCol = \"label\", featuresCol = \"features\")\n",
    "\n",
    "### Support Vector Machines \n",
    "l_svc = LinearSVC(maxIter=10, regParam=0.1)\n",
    "ovr_svc = OneVsRest(classifier = l_svc, labelCol = \"label\", featuresCol = \"features\")\n",
    "\n",
    "### Creating the labelConvertor transformer \n",
    "labelConverter = IndexToString(inputCol = \"prediction\", \n",
    "                               outputCol = \"predicted_sentiment\", \n",
    "                               labels= [\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb7799c3-1275-4927-a046-5b245236f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the pipeline for Logistic Regression \n",
    "pipeline_lr = Pipeline(stages=[h_t, idf_model, \n",
    "                               string_indexer_target, \n",
    "                               vectorAssembler_features, \n",
    "                               ovr, labelConverter])\n",
    "\n",
    "### Defining the pipeline for Naive Bayes \n",
    "pipeline_nb = Pipeline(stages=[h_t, idf_model, \n",
    "                               string_indexer_target, \n",
    "                               vectorAssembler_features, \n",
    "                               nb, labelConverter])\n",
    "\n",
    "### Defining the pipeline for Linear Support Vector Machines \n",
    "pipeline_svc = Pipeline(stages=[h_t, idf_model, \n",
    "                                string_indexer_target, \n",
    "                                vectorAssembler_features, \n",
    "                                ovr_svc, labelConverter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55d0cd8c-bce4-493f-b6cd-a2b2ed5f12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 02:07:39 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 02:08:01 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 02:08:21 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 02:08:40 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "[Stage 1424:================================================>     (24 + 3) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.907908\n",
      "Test Error = 0.0920925\n",
      "Precision = 0.91925\n",
      "Recall = 0.927843\n",
      "F1 Score = 0.907904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.907908</td>\n",
       "      <td>0.91925</td>\n",
       "      <td>0.927843</td>\n",
       "      <td>0.907904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score\n",
       "0  0.907908    0.91925  0.927843  0.907904"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying five cross validation for Logistic Regression \n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0, 0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval = CrossValidator(estimator = pipeline_lr,\n",
    "                          estimatorParamMaps = paramGrid_lr,\n",
    "                          evaluator = MulticlassClassificationEvaluator(),\n",
    "                          numFolds = 5) \n",
    "\n",
    "cvModel = crossval.fit(train_data)\n",
    "\n",
    "### Getting the best model \n",
    "best_model = cvModel.bestModel\n",
    "prediction_cv = best_model.transform(test_data)\n",
    "\n",
    "### Getting the accuracy and printing it \n",
    "evaluator_cv = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "accuracy_lr = evaluator_cv.evaluate(prediction_cv)\n",
    "evaluator_cv_pre = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"precisionByLabel\")\n",
    "precision_lr = evaluator_cv_pre.evaluate(prediction_cv)\n",
    "evaluator_cv_rec = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"recallByLabel\")\n",
    "recall_lr = evaluator_cv_rec.evaluate(prediction_cv)\n",
    "evaluator_cv_f1 = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"f1\")\n",
    "f1_lr = evaluator_cv_f1.evaluate(prediction_cv)\n",
    "\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy_lr)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_lr))\n",
    "print(\"Precision = %g\" % precision_lr)\n",
    "print(\"Recall = %g\" % recall_lr)\n",
    "print(\"F1 Score = %g\" % f1_lr)\n",
    "\n",
    "metrics_lr_dict = {\"Accuracy\" : [accuracy_lr],\n",
    "                   \"Precision\" : [precision_lr],\n",
    "                   \"Recall\" : [recall_lr], \n",
    "                   \"F1 Score\" : [f1_lr]}\n",
    "\n",
    "metrics_lr_df = pd.DataFrame(metrics_lr_dict)\n",
    "metrics_lr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e9cdce3-f539-4ea9-af30-b87bc0209477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.724425\n",
      "Test Error = 0.275575\n",
      "Precision = 0.741275\n",
      "Recall = 0.797289\n",
      "F1 Score = 0.723131\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.724425</td>\n",
       "      <td>0.741275</td>\n",
       "      <td>0.797289</td>\n",
       "      <td>0.723131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score\n",
       "0  0.724425   0.741275  0.797289  0.723131"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fitting and transforming the Naive Bayes Model \n",
    "nb_model = pipeline_nb.fit(train_data)\n",
    "\n",
    "prediction_nb = nb_model.transform(test_data)\n",
    "\n",
    "## Evaluating the metrics \n",
    "evaluator_nb = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "accuracy_nb = evaluator_nb.evaluate(prediction_nb)\n",
    "evaluator_nb_pre = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"precisionByLabel\")\n",
    "precision_nb = evaluator_nb_pre.evaluate(prediction_nb)\n",
    "evaluator_nb_rec = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"recallByLabel\")\n",
    "recall_nb = evaluator_nb_rec.evaluate(prediction_nb)\n",
    "evaluator_nb_f1 = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"f1\")\n",
    "f1_nb = evaluator_nb_f1.evaluate(prediction_nb)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy_nb)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_nb))\n",
    "print(\"Precision = %g\" % precision_nb)\n",
    "print(\"Recall = %g\" % recall_nb)\n",
    "print(\"F1 Score = %g\" % f1_nb)\n",
    "\n",
    "metrics_nb_dict = {\"Accuracy\" : [accuracy_nb],\n",
    "                   \"Precision\" : [precision_nb],\n",
    "                   \"Recall\" : [recall_nb], \n",
    "                   \"F1 Score\" : [f1_nb]}\n",
    "\n",
    "metrics_nb_df = pd.DataFrame(metrics_nb_dict)\n",
    "metrics_nb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4efd71d3-b0c4-48e4-a2bf-6521f10b41f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.916524\n",
      "Test Error = 0.0834762\n",
      "Precision = 0.926347\n",
      "Recall = 0.939276\n",
      "F1 Score = 0.916418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916524</td>\n",
       "      <td>0.926347</td>\n",
       "      <td>0.939276</td>\n",
       "      <td>0.916418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall  F1 Score\n",
       "0  0.916524   0.926347  0.939276  0.916418"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Applying five cross validation for Support Vector Machines \n",
    "paramGrid_svc = ParamGridBuilder() \\\n",
    "    .addGrid(l_svc.regParam, [1, 0.1, 0.01]) \\\n",
    "    .build()\n",
    "\n",
    "crossval_svc = CrossValidator(estimator = pipeline_svc,\n",
    "                          estimatorParamMaps = paramGrid_svc,\n",
    "                          evaluator = MulticlassClassificationEvaluator(),\n",
    "                          numFolds = 5)  \n",
    "\n",
    "svc_model_cv = crossval_svc.fit(train_data)\n",
    "\n",
    "best_model = svc_model_cv.bestModel\n",
    "prediction_cv_svc = best_model.transform(test_data)\n",
    "\n",
    "evaluator_cv_svc = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "accuracy_svc = evaluator_cv_svc.evaluate(prediction_cv_svc)\n",
    "evaluator_svc_pre = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"precisionByLabel\")\n",
    "precision_svc = evaluator_svc_pre.evaluate(prediction_cv_svc)\n",
    "evaluator_svc_rec = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"recallByLabel\")\n",
    "recall_svc = evaluator_svc_rec.evaluate(prediction_cv_svc)\n",
    "evaluator_svc_f1 = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"f1\")\n",
    "f1_svc = evaluator_svc_f1.evaluate(prediction_cv_svc)\n",
    "\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy_svc)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_svc))\n",
    "print(\"Precision = %g\" % precision_svc)\n",
    "print(\"Recall = %g\" % recall_svc)\n",
    "print(\"F1 Score = %g\" % f1_svc)\n",
    "\n",
    "metrics_svc_dict = {\"Accuracy\" : [accuracy_svc],\n",
    "                   \"Precision\" : [precision_svc],\n",
    "                   \"Recall\" : [recall_svc], \n",
    "                   \"F1 Score\" : [f1_svc]}\n",
    "\n",
    "metrics_svc_df = pd.DataFrame(metrics_svc_dict)\n",
    "metrics_svc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05023612-8537-43f4-a66d-c56cc73ee77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [metrics_lr_df, metrics_nb_df, metrics_svc_df]\n",
    "\n",
    "metrics_df = pd.concat(metrics)\n",
    "metrics_df.index = [\"Logistic Regression Cross Validation\", \"Mulitnomial Naive Bayes\", \"SVM Cross Validation\"]\n",
    "metrics_df = metrics_df.round(2)\n",
    "### Saving to csv \n",
    "metrics_df.to_csv(\"sentiment_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a823724-08c4-47ce-8ed1-c98b50675bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 05:03:20 WARN TaskSetManager: Stage 3801 contains a task of very large size (4187 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/13 05:03:38 WARN TaskSetManager: Stage 3812 contains a task of very large size (4187 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/13 05:03:51 WARN TaskSetManager: Stage 3823 contains a task of very large size (2097 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/13 05:03:55 WARN TaskSetManager: Stage 3827 contains a task of very large size (2097 KiB). The maximum recommended task size is 1000 KiB.\n",
      "23/04/13 05:03:59 WARN TaskSetManager: Stage 3831 contains a task of very large size (2097 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Saving the SVM cross-validation model \n",
    "svc_model_cv.save(\"s3a://ppol567-llj40-bucket-4/models/svc_model_cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e80348f-cacf-42b0-a98e-a2ca6e17c996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 05:14:27 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "[Stage 3888:====================================================> (26 + 1) / 27]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.916524\n",
      "Test Error = 0.0834762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Loading in the saved model and assessing the accuracy \n",
    "svc_model_read = CrossValidatorModel.read().load(\"s3a://ppol567-llj40-bucket-4/models/svc_model_cv\")\n",
    "best_model_svc = svc_model_read.bestModel\n",
    "\n",
    "      \n",
    "prediction_cv_svc_read = svc_model_read.bestModel.transform(test_data)\n",
    "evaluator_cv_read = MulticlassClassificationEvaluator(labelCol = \"label\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "accuracy = evaluator_cv_read.evaluate(prediction_cv_svc_read)\n",
    "\n",
    "print(\"Accuracy = %g\" % accuracy)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ac061c1-13e9-4333-b6a2-a26af65a1be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 05:23:11 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 05:23:50 WARN DAGScheduler: Broadcasting large task binary with size 26.4 MiB\n",
      "23/04/13 05:23:51 WARN DAGScheduler: Broadcasting large task binary with size 26.4 MiB\n",
      "[Stage 3895:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------+\n",
      "|predicted_sentiment| count|\n",
      "+-------------------+------+\n",
      "|           Positive|175427|\n",
      "|            Neutral|187431|\n",
      "|           Negative|273144|\n",
      "+-------------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction_cv_svc_read.groupby(\"predicted_sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad4a0902-f4a8-497e-a072-48d6cbed73a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 05:25:17 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "[Stage 3896:>                                                       (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|     id|predicted_sentiment|\n",
      "+-------+-------------------+\n",
      "|hsgr728|           Positive|\n",
      "|hsgrg1t|            Neutral|\n",
      "|hsgrhpz|           Negative|\n",
      "|hsgrv8w|            Neutral|\n",
      "|hsgs6gc|           Negative|\n",
      "+-------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction_cv_svc_read.select(\"id\", \"predicted_sentiment\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca450ec7-be1f-4d46-94ed-fae85a4962d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3177282\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = true)\n",
      " |-- Polarity_Scores: string (nullable = true)\n",
      " |-- Compound_Score: string (nullable = true)\n",
      " |-- Positive_Score: string (nullable = true)\n",
      " |-- Negative_Score: string (nullable = true)\n",
      " |-- Neutral_Score: string (nullable = true)\n",
      " |-- Sentiment_Label: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3902:==============================================>       (24 + 4) / 28]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16171595\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- created_date: string (nullable = true)\n",
      " |-- date_clean: date (nullable = true)\n",
      " |-- body: string (nullable = true)\n",
      " |-- controversiality: long (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Getting the anti-join of to get the unlabled comments\n",
    "print(df_sentiment.count())\n",
    "df_sentiment.printSchema()\n",
    "print(df_com_processed.count())\n",
    "df_com_processed.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11044f02-9602-4858-8dd7-fd9bbc71a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12994313"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment_req = df_sentiment.select(\"id\", \"submission_id\", \"finished_clean\")\n",
    "df_com_req = df_com_processed.select(\"id\", \"submission_id\", \"finished_clean\")\n",
    "### Applying anti-join \n",
    "df_unlabel = df_com_req.join(df_sentiment_req, ((df_com_req.id == df_sentiment_req.id) & \\\n",
    "                             (df_com_req.submission_id == df_sentiment_req.submission_id) \\\n",
    "                             & (df_com_req.finished_clean == df_sentiment_req.finished_clean)), \"leftanti\")\n",
    "df_unlabel.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8d135b7-3d73-4a6d-82c4-ccb67acf3768",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generating sentiment labels for unlabeled comments \n",
    "df_unlabel = df_unlabel.withColumn(\"string_form\", f.concat_ws(\" \", f.col(\"finished_clean\")))\n",
    "\n",
    "### Further cleaning of text \n",
    "### Removing comments from subreddit moderators \n",
    "df_unlabel = df_unlabel.withColumn(\"moderator\", f.col(\"string_form\").rlike(\"(?i)moderator\"))\n",
    "df_unlabel_clean = df_unlabel.filter(f.col(\"moderator\") == False)\n",
    "\n",
    "### Removing empty rows \n",
    "df_unlabel_clean = df_unlabel_clean.filter(f.col(\"string_form\") != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "274407a1-356a-4204-99ac-303172a6c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The data is now ready to be labeled using our best performing model \n",
    "best_model_svc = svc_model_read.bestModel\n",
    "\n",
    "### Avoiding the String-Indexer stage \n",
    "prediction_unlabel_clean = svc_model_read.bestModel.stages[0].transform(df_unlabel_clean) ## Term-Frequency\n",
    "prediction_unlabel_clean = svc_model_read.bestModel.stages[1].transform(prediction_unlabel_clean) ## Inverse Document Frequency \n",
    "prediction_unlabel_clean = svc_model_read.bestModel.stages[3].transform(prediction_unlabel_clean) ## Vector Assembler\n",
    "prediction_unlabel_clean = svc_model_read.bestModel.stages[4].transform(prediction_unlabel_clean) ## Model \n",
    "prediction_unlabel_clean = svc_model_read.bestModel.stages[5].transform(prediction_unlabel_clean) ## Label Convertor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c14361dd-44e1-4345-ab21-b136434356c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 06:08:01 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 06:11:37 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "23/04/13 06:11:38 WARN DAGScheduler: Broadcasting large task binary with size 26.5 MiB\n",
      "[Stage 3936:============================>                           (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|predicted_sentiment|  count|\n",
      "+-------------------+-------+\n",
      "|           Positive|3499815|\n",
      "|            Neutral|3743620|\n",
      "|           Negative|5471710|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction_unlabel_clean.groupby(\"predicted_sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af0495c2-9db7-4c9f-9548-ab21185ff602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/04/13 06:14:53 WARN DAGScheduler: Broadcasting large task binary with size 26.7 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "prediction_unlabel_clean.select(\"id\", \"submission_id\", \"finished_clean\", \"string_form\", \"predicted_sentiment\").write.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/sentiment_model_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30b32319-f14c-4b7a-8fd6-87af7e60b972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = true)\n",
      " |-- Sentiment_Label: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12715145\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = true)\n",
      " |-- Polarity_Scores: string (nullable = true)\n",
      " |-- Compound_Score: string (nullable = true)\n",
      " |-- Positive_Score: string (nullable = true)\n",
      " |-- Negative_Score: string (nullable = true)\n",
      " |-- Neutral_Score: string (nullable = true)\n",
      " |-- Sentiment_Label: string (nullable = true)\n",
      "\n",
      "3177282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Reading in the predicted label data and combining it with the labeled dataset \n",
    "prediction_label_df = spark.read.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/sentiment_model_labels\")\n",
    "### Renaming predicted_sentiment column as Sentiment_Label\n",
    "prediction_label_df = prediction_label_df.withColumnRenamed(\"predicted_sentiment\", \"Sentiment_Label\")\n",
    "prediction_label_df.printSchema()\n",
    "\n",
    "print(prediction_label_df.count())\n",
    "\n",
    "df_sentiment.printSchema()\n",
    "print(df_sentiment.count())\n",
    "\n",
    "final_sentiment_df = df_sentiment.select(\"id\", \"submission_id\", \"finished_clean\", \"string_form\", \"Sentiment_Label\").union(prediction_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465c92db-a102-4abd-8581-57d5df9702ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15892427\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- submission_id: string (nullable = true)\n",
      " |-- finished_clean: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- string_form: string (nullable = true)\n",
      " |-- Sentiment_Label: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+--------------------+--------------------+---------------+\n",
      "|     id|submission_id|      finished_clean|         string_form|Sentiment_Label|\n",
      "+-------+-------------+--------------------+--------------------+---------------+\n",
      "|iuzifkc|       ylmqn0|[gtan, oppressive...|gtan oppressive p...|       Positive|\n",
      "|iuzifu3|       yljxj2|[disagree, argument]|   disagree argument|       Negative|\n",
      "|iuzigtq|       ylmqn0|[gtwe, forgive, r...|gtwe forgive russ...|       Positive|\n",
      "|iuzik4u|       yljxj2|[645, year, calcu...|645 year calculat...|        Neutral|\n",
      "|iuzikej|       ykrn8h|           [urukhai]|             urukhai|        Neutral|\n",
      "+-------+-------------+--------------------+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(final_sentiment_df.count())\n",
    "final_sentiment_df.printSchema()\n",
    "final_sentiment_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4278fd5-6678-436e-aedd-2b7eaf3c47f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Saving final_sentiment_df to S3\n",
    "final_sentiment_df.write.parquet(\"s3a://ppol567-llj40-bucket-4/worldnews/final_complete_sentiment_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f53a05b2-ad3a-4c05-970a-e1e575443bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment_count = final_sentiment_df.groupby(\"Sentiment_Label\")\\\n",
    "                                    .agg(f.count(\"Sentiment_Label\").alias(\"Number of Comments\")) \\\n",
    "                                    .orderBy(f.col(\"Number of Comments\").desc()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0fbf2862-2ab5-4ddf-9704-f32aee508593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Percentage of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>6818525</td>\n",
       "      <td>42.90%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>4621903</td>\n",
       "      <td>29.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>4451999</td>\n",
       "      <td>28.01%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment_Label  Number of Comments Percentage of Comments\n",
       "0        Negative             6818525                 42.90%\n",
       "1         Neutral             4621903                 29.08%\n",
       "2        Positive             4451999                 28.01%"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = sentiment_count[\"Number of Comments\"].sum()\n",
    "sentiment_count[\"Percentage of Comments\"] = (sentiment_count[\"Number of Comments\"]/total * 100).map(\"{:,.2f}%\".format)\n",
    "sentiment_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "503fd65b-d7af-4355-939c-955764acfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count.to_csv(\"sentiment_labels_count.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37a53da9-d03c-4312-abb0-8957e94bc599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### Only accessing live thread submissions and comments \n",
    "df_live_sub = df_sub_processed.filter(f.col(\"Live_Thread\") == 1)\n",
    "\n",
    "### Getting the live thread ids \n",
    "df_sub_id = df_live_sub.select(\"id\").collect()\n",
    "df_sub_live_id = [row.id for row in df_sub_id]\n",
    "\n",
    "### Extracting the live thread comments \n",
    "df_live_com = final_sentiment_df.filter(f.col(\"submission_id\").isin(df_sub_live_id))\n",
    "total = df_live_com.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "196035d1-4646-4aa4-9046-fcabaf2b3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sentiment_count_live_thread = df_live_com.groupby(\"Sentiment_Label\")\\\n",
    "                                         .agg(f.count(\"Sentiment_Label\").alias(\"Number of Comments\"),\n",
    "                                              (f.count(\"Sentiment_Label\")/total*100).alias(\"Percentage of Comments\")) \\\n",
    "                                         .orderBy(f.col(\"Number of Comments\").desc()).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "095e5a93-3bf0-4473-bf8c-a002a9dbc9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Number of Comments</th>\n",
       "      <th>Percentage of Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>749444</td>\n",
       "      <td>41.91%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>528800</td>\n",
       "      <td>29.57%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neutral</td>\n",
       "      <td>509961</td>\n",
       "      <td>28.52%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment_Label  Number of Comments Percentage of Comments\n",
       "0        Negative              749444                 41.91%\n",
       "1        Positive              528800                 29.57%\n",
       "2         Neutral              509961                 28.52%"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_count_live_thread[\"Percentage of Comments\"] = sentiment_count_live_thread[\"Percentage of Comments\"].map(\"{:,.2f}%\".format)\n",
    "sentiment_count_live_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dced8cfd-6b34-4a4d-a842-d9f546d0f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_count_live_thread.to_csv(\"sentiment_labels_live_threads.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24dff445-ccf2-40da-ae13-e03bcda2b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
